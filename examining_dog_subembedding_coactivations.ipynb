{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import time\n",
    "import ast\n",
    "import collections\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### #### read val labels\n",
    "\n",
    "with open('label_dictionary.json','r') as fp:\n",
    "    label_dictionary_old = json.load(fp)\n",
    "    \n",
    "print(label_dictionary_old)\n",
    "\n",
    "num_selected = 1000\n",
    "\n",
    "val_labels = np.load('random_pairs_2k/val_labels_processed.npy')[:num_selected]\n",
    "\n",
    "random_subembeddings = np.load('random_pairs_2k/cumulative_sub_embedding_output_1_random.npy')[:num_selected,:]\n",
    "#random_embeddings = random_embeddings+np.random.randn(*random_embeddings.shape)/10000\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute 90th Percentile Thresholds for Sub-Embeddings Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get embedding percentile thresholds\n",
    "\n",
    "subembeddings_for_percentile_comp= np.squeeze(np.load('alexnet_imgnet_sub_embeddings_prelu_noise.npy'))\n",
    "subembeddings_for_percentile_comp = subembeddings_for_percentile_comp + np.random.randn(*subembeddings_for_percentile_comp.shape)/10000\n",
    "sorted_indices_subembedding = np.argsort(subembeddings_for_percentile_comp,axis = 0)\n",
    "indices_90_subembedding = sorted_indices_subembedding[900,:]\n",
    "subembedding_threshold_90 = subembeddings_for_percentile_comp[indices_90_subembedding, range(4096)].reshape(1,4096)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute Number of Co-active Features Between Sub-Embeddings of All Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'random_subembeddings' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-e1cc0fc87742>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrandom_subemb_active\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mrandom_subembeddings\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0msubembedding_threshold_90\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mrandom_subemb_active_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom_subemb_active\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mrandom_subemb_active_expanded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_subemb_active\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mrandom_subemb_active_t_expanded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_subemb_active_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mco_active_feats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom_subemb_active_expanded\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mrandom_subemb_active_t_expanded\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'random_subembeddings' is not defined"
     ]
    }
   ],
   "source": [
    "random_subemb_active = (random_subembeddings >= subembedding_threshold_90)*1\n",
    "random_subemb_active_t = random_subemb_active.T\n",
    "random_subemb_active_expanded = np.expand_dims(random_subemb_active, axis=2)\n",
    "random_subemb_active_t_expanded = np.expand_dims(random_subemb_active_t, axis=0)\n",
    "co_active_feats = random_subemb_active_expanded*random_subemb_active_t_expanded\n",
    "co_active_features_random_subemb = np.matmul(random_subemb_active,random_subemb_active_t)\n",
    "co_active_features_random_subemb_sorted = np.argsort(-co_active_features_random_subemb,axis = 1)\n",
    "average_random_subemb = np.mean(co_active_features_random_subemb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute and Plot Histogram of Number of Co-Active Features Between All Pairs of Sub-Embeddings (sanity-check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins=np.linspace(np.min(co_active_features_random_subemb), np.max(co_active_features_random_subemb),50)\n",
    "plt.figure(figsize=(7,7))\n",
    "plt.title('histograms of number of co-active features in the sub-embedding \\n average number of co-active features (sub-embedding layer) = '+str(average_random_subemb), fontsize=14)\n",
    "plt.hist(co_active_features_random_subemb.flatten(),bins=bins, label = 'subembedding', alpha = 0.5)\n",
    "plt.ylabel('count',fontsize=14)\n",
    "plt.xlabel('number of co-active features',fontsize=14)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dictionary = {}\n",
    "for key in label_dictionary_old:\n",
    "    label_dictionary[float(key)] = label_dictionary_old[key]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute Number of Co-Active Pairs Resulting from Same and Different Classes Across All-Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "feats_same = np.zeros(4096)\n",
    "feats_diff = np.zeros(4096)\n",
    "\n",
    "feats_num_unique_classes_same = np.zeros(4096)\n",
    "#feats_unique_classes_same = {}\n",
    "\n",
    "feats_num_unique_classes_diff = np.zeros(4096)\n",
    "#feats_unique_classes_diff = {}\n",
    "\n",
    "feature_cloud = collections.defaultdict(str)\n",
    "\n",
    "for feature in range(4096):\n",
    "    feats_same_classes = []\n",
    "    feats_diff_classes = []\n",
    "    \n",
    "    # get sum of activations for a features\n",
    "    co_active_sum_of_activations_sorted_args = np.load('co_active_sum_of_sub_activations_sorted_args_'+str(feature)+'.npy')\n",
    "    \n",
    "    for ind in range(0,len(co_active_sum_of_activations_sorted_args),2):\n",
    "        x = int(co_active_sum_of_activations_sorted_args[ind]/num_selected)\n",
    "        y = co_active_sum_of_activations_sorted_args[ind]%num_selected\n",
    "        \n",
    "        \n",
    "        if co_active_feats[x,feature,y] == 0:\n",
    "            break\n",
    "            \n",
    "        if x == y:\n",
    "            continue\n",
    "        else:\n",
    "            class_x = val_labels[x]\n",
    "            class_y = val_labels[y]\n",
    "            \n",
    "            label_x = label_dictionary[class_x]\n",
    "            label_y = label_dictionary[class_y]\n",
    "            \n",
    "            feature_cloud[feature] = feature_cloud[feature]+' '+label_x+' '+label_y\n",
    "            if class_x != class_y:\n",
    "                feats_diff[feature] += 1\n",
    "                if class_x not in feats_diff_classes:\n",
    "                    feats_diff_classes.append(class_x)\n",
    "                if class_y not in feats_diff_classes:\n",
    "                    feats_diff_classes.append(class_y)\n",
    "            else:\n",
    "                feats_same[feature] += 1\n",
    "                if class_x not in feats_same_classes:\n",
    "                    feats_same_classes.append(class_x)\n",
    "                \n",
    "    feats_num_unique_classes_same[feature] = len(feats_same_classes)\n",
    "    #feats_unique_classes_same[feature] = feats_same_classes\n",
    "    feats_num_unique_classes_diff[feature] = len(feats_diff_classes)\n",
    "    #feats_unique_classes_diff[feature] = feats_diff_classes\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Histogram of Number of Co-Active Pairs Resulting from Same and Different Classes Across All Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins=np.linspace(np.min([np.min(feats_same),np.min(feats_diff)]),np.max([np.max(feats_same),np.max(feats_diff)]),100)\n",
    "plt.figure(figsize=(10,20))\n",
    "fig, axs = plt.subplots(1,2, figsize=(20,10))\n",
    "axs[0].set_title('histograms of number of co-activations for \\n image-pairs from same class \\n ', fontsize=14)\n",
    "axs[0].hist(feats_same,bins=15, label = 'co-activation from same-class')\n",
    "axs[0].set_ylabel('count',fontsize=14)\n",
    "axs[0].set_xlabel('number of co-active sub-embedding features',fontsize=14)\n",
    "axs[0].legend()\n",
    "axs[1].set_title('histograms of number of co-activations for \\n image-pairs from different class', fontsize=14)\n",
    "axs[1].hist(feats_diff,bins=15, label = 'co-activation from different-class', color='orange')\n",
    "axs[1].set_ylabel('count',fontsize=14)\n",
    "axs[1].set_xlabel('number of co-active sub-embedding features',fontsize=14)\n",
    "axs[1].legend()\n",
    "plt.ylabel('count',fontsize=14)\n",
    "plt.xlabel('number of co-active sub-embedding features',fontsize=14)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Histogram of Number Unique Classes Across Image-Pairs With the Same Class Label and Across Image-Pairs With the Different Class Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins=np.linspace(np.min([np.min(feats_same),np.min(feats_diff)]),np.max([np.max(feats_same),np.max(feats_diff)]),100)\n",
    "fig, axs = plt.subplots(1,2, figsize=(20,10))\n",
    "axs[0].set_title('histograms of number of unique classes per co-active feature \\n for image-pairs with the same class label', fontsize=14)\n",
    "axs[0].hist(feats_num_unique_classes_same,bins=10, label = 'co-activation from different-class')\n",
    "axs[0].set_ylabel('count',fontsize=14)\n",
    "axs[0].set_xlabel('number of unique classes per co-active feature',fontsize=14)\n",
    "axs[0].legend()\n",
    "\n",
    "print(max(feats_num_unique_classes_diff))\n",
    "axs[1].set_title('histograms of number of unique classes per co-active feature \\n for image-pairs with the different class labels', fontsize=14)\n",
    "axs[1].hist(feats_num_unique_classes_diff,bins=10, label = 'co-activation from different-class', color='orange')\n",
    "axs[1].set_ylabel('count',fontsize=14)\n",
    "axs[1].set_xlabel('number of unique classes per co-active feature',fontsize=14)\n",
    "axs[1].legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Display Top-10 Pairs (With Highest Sum of Feature Values) for the Purest Co-Active Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(np.max(feats_same))\n",
    "print(np.min(feats_same))\n",
    "# get max_co_active_features\n",
    "\n",
    "sorted_feats_same = np.argsort(-feats_same.flatten())[:10]\n",
    "\n",
    "\n",
    "print('Image Pairs With Highest Sum of Sub-Embedding Co-Activation Values for Most Homogenous Features')\n",
    "\n",
    "\n",
    "for feature in sorted_feats_same:\n",
    "    # get sum of activations for a features\n",
    "    print('feature ',feature)\n",
    "    print('number of co-active pairs from same class = ',feats_same[feature])\n",
    "    print('number of co-active pairs from diff class = ',feats_diff[feature])\n",
    "    \n",
    "    #plot the feature cloud\n",
    "    \n",
    "    wordcloud = WordCloud(width = 3000, height = 2000, random_state=1, background_color='salmon', colormap='Pastel1', collocations=False, stopwords = STOPWORDS).generate(feature_cloud[feature])\n",
    "    plt.imshow(wordcloud, interpolation = 'bilinear')\n",
    "    plt.axis('off')\n",
    "    plt.title('Word Cloud Made Using Class Labels from Co-Active Pairs')\n",
    "    co_active_sum_of_activations_sorted_args = np.load('co_active_sum_of_sub_activations_sorted_args_'+str(feature)+'.npy')\n",
    "    list_of_sorted_indices = []\n",
    "    for ind in range(len(co_active_sum_of_activations_sorted_args)):\n",
    "        x = int(co_active_sum_of_activations_sorted_args[ind]/num_selected)\n",
    "        y = co_active_sum_of_activations_sorted_args[ind]%num_selected\n",
    "        list_of_sorted_indices.append((x,y))\n",
    "           \n",
    "    # display pairs with highest activations\n",
    "    pair_count = 1\n",
    "    for ind in range(0,10,2):\n",
    "        x,y = list_of_sorted_indices[ind][0], list_of_sorted_indices[ind][1]\n",
    "        if co_active_feats[x,feature,y] == 0:\n",
    "            break\n",
    "        if x != y:\n",
    "            class_x = val_labels[x]\n",
    "            class_y = val_labels[y]\n",
    "            label_x = label_dictionary[class_x]\n",
    "            label_y = label_dictionary[class_y]\n",
    "            fig,axs = plt.subplots(1,2, figsize = (8,4))\n",
    "            print('Pair:',pair_count)\n",
    "            pair_count += 1\n",
    "            fig.tight_layout(pad=2)\n",
    "            plt.subplots_adjust(top=1.0)\n",
    "            img = mpimg.imread('random_pairs_cumulative/count_'+str(x)+'.jpg')\n",
    "            axs[0].imshow(img, aspect=\"auto\")\n",
    "            axs[0].axis('off')\n",
    "            axs[0].set_title('class: '+label_x,fontsize=10)\n",
    "            img = mpimg.imread('random_pairs_cumulative/count_'+str(y)+'.jpg')\n",
    "            axs[1].imshow(img, aspect=\"auto\")\n",
    "            axs[1].axis('off')\n",
    "            axs[1].set_title('class: '+label_y,fontsize=10)\n",
    "            plt.show()\n",
    "            plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Display Top-10 Pairs (With Highest Sum of Feature Values) for the Least-Pure Co-Active Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# get min_co_active_features\n",
    "sorted_feats_diff = np.argsort(-feats_diff.flatten())[:10]\n",
    "\n",
    "print('Image Pairs With Highest Sum of Sub-Embedding Co-Activation Values for Least Homogenous Features')\n",
    "\n",
    "for feature in sorted_feats_diff:\n",
    "    print('\\n\\nfeature: ',feature)\n",
    "    print('num co-activations from different class :',feats_diff[feature])\n",
    "    print('num co-activations from the same class :',feats_same[feature],'\\n\\n')\n",
    "    \n",
    "    wordcloud = WordCloud(width = 3000, height = 2000, random_state=1, background_color='salmon', colormap='Pastel1', collocations=False, stopwords = STOPWORDS).generate(feature_cloud[feature])\n",
    "    plt.imshow(wordcloud, interpolation = 'bilinear')\n",
    "    plt.axis('off')\n",
    "    plt.title('Word Cloud Made Using Class Labels from Co-Active Pairs')\n",
    "    co_active_sum_of_activations_sorted_args = np.load('co_active_sum_of_sub_activations_sorted_args_'+str(feature)+'.npy')\n",
    "    \n",
    "    co_active_current_feat = co_active_feats[:,feature,:]\n",
    "    current_activations_all_activations = random_subembeddings[:,feature].reshape(1,-1)\n",
    "    current_activations_all_activations_t = current_activations_all_activations.T\n",
    "    sum_of_activations = current_activations_all_activations+current_activations_all_activations_t\n",
    "    co_active_sum_of_activations = np.argsort(-(sum_of_activations*co_active_current_feat).flatten())\n",
    "    list_of_sorted_indices = []\n",
    "    for ind in range(len(co_active_sum_of_activations)):\n",
    "        x = int(co_active_sum_of_activations[ind]/num_selected)\n",
    "        y = co_active_sum_of_activations[ind]%num_selected\n",
    "        list_of_sorted_indices.append((x,y))\n",
    "           \n",
    "    # display pairs with highest activations\n",
    "    for ind in range(0,10,2):\n",
    "        x,y = list_of_sorted_indices[ind][0], list_of_sorted_indices[ind][1]\n",
    "        if x != y:\n",
    "            class_x = val_labels[x]\n",
    "            class_y = val_labels[y]\n",
    "            label_x = label_dictionary[class_x]\n",
    "            label_y = label_dictionary[class_y]\n",
    "            print('Pair:',pair_count)\n",
    "            pair_count += 1\n",
    "            fig,axs = plt.subplots(1,2, figsize = (8,4))\n",
    "            fig.tight_layout(pad=2)\n",
    "            plt.subplots_adjust(top=1.0)\n",
    "            img = mpimg.imread('random_pairs_cumulative/count_'+str(x)+'.jpg')\n",
    "            axs[0].imshow(img, aspect=\"auto\")\n",
    "            axs[0].axis('off')\n",
    "            axs[0].set_title('class: '+str(class_x),fontsize=10)\n",
    "            img = mpimg.imread('random_pairs_cumulative/count_'+str(y)+'.jpg')\n",
    "            axs[1].imshow(img, aspect=\"auto\")\n",
    "            axs[1].axis('off')\n",
    "            axs[1].set_title('class: '+str(class_y),fontsize=10)\n",
    "            plt.show()\n",
    "            plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
